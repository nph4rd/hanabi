max_steps = 20

[ckpt] # Checkpoint at the end of training

[model]
name = "PrimeIntellect/Qwen3-1.7B"

[data]
name = "nph4rd/hanabi"
seq_len = 1024
batch_size = 64
micro-batch-size = 1

[optim]
lr = 1e-5
